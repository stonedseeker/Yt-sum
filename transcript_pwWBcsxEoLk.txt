You suck at prompting. It's okay, I did too, but I got tired of asking AI to do things and getting garbage. Getting results like this, when I'm expecting this. Like, have you ever yelled at Chad J.P.T. like a really insult of it? Because you're so frustrated with the results, if you haven't, you're not using it enough. It's those moments, that frustration that makes me think one of two things. One, AI is dumb, and I'm not going to use it anymore. Those naysayers are right. Or two, I'm dumb, and I have no idea how to use AI. I most often feel like option two, and this was confirmed when I asked the prompt father himself what I was doing wrong. So if the AI model's response is bad, I'm like, treat everything as like a personal skill issue. The problem is me. It's a skill issue. So I went deep, too deep. I took all the top prompting courses on Coursera, I read all the official prompting docs and thrombed at Google, OpenAI, and then I asked all the experts the best prompt engineers I know, Daniel Miesler, Eric Pope, Joseph Vacker, and I think I figured it out. So in this video, let's get good. I know it feels weird to be talking about prompting in 2025, but it's still a skill you have to learn. I pulled you guys, asking, hey, how do you feel about your skills? Most of you are pretty confident. That might change after you see this video. Others are like, I don't know what I'm doing. This video is for you. Actually, it's for all of you. Watch this video. I made this for you. And we're going to have some fun with it, so I've got this Cloudflare apology email. We're going to take this garbage and turn it into something amazing with foundational concepts. We're going to keep increasing our skills as we learn new things, and in the end, I actually learned something pretty crazy. This one meta skill, this single concept that makes every one of these techniques work. I got it from the experts. So get your coffee ready. It's time to learn prompting in 2025. Let's go. On by the way, thank you to Coursera for sponsoring this video and helping me dive deep in learning how to prompt. Okay, now I can go. I was trying this basic prompt that produces this garbage output for a Cloudflare apology email into something amazing. But hold on, before you fix your prompting, you need to understand what prompting really is, and I know you think you know, but you actually don't know. Because most people, including me, get this fundamentally wrong. But I'll give you this. Prompting essentially is just asking AI to do stuff. And it almost feels like talking to a human, sometimes we forget that it's not. But you have to remember, you're talking to a computer. And the vendor built university course on prompting, which is awesome. Dr. Jules White defines a prompt like this. It is a call to action to the large language model. It's a call to action. But he teaches that a prompt just isn't a question. It's a program. You aren't asking the AI. You're programming it with words. Every time we actually write something, chat GBT needs to format it in a particular structure that we've given it. We've wrote a program that tells it what to do. We need that mentality because LLMs don't think like we do. They are prediction engines, as Dr. White says. When you understand that an LLM is just super advanced auto-complete, that'll change your perspective. Like, check this out. I want to choose a different AI. Let's go with Google. Gemini. I want to see if it can predict the next word in this phrase. And I'm trying to get it to copy me. My catch phrase you need to learn Docker right now or anything right now, prompting right now. Let's see what happens. So it didn't, it gave me a generic answer, a generic completion. And that's why they call the results of like a prompt a completion because they're just completing or predicting what you're wanting. They're not thinking about it. This response right here was statistically the best response. According to it. But if we get more specific, and I just mean a tiny bit specific, I'll open up a new prompt. So we got something fresh. Notice this time I'm just putting into placeholders and exclamation points. What I'm hoping is that it's seen enough examples like this to go, oh, I know what that is going to be. I can predict that. Let's see. Come on. I got it. It's studying me. I guess that because, and I say guess because it is guessing because it's seen patterns like that before. I'll even ask it why it shows right now. Let me see. By technology focused YouTube creators, I just want to say my name. There we go. So what I want to hit home is that you're not asking a question. You're starting a pattern. As you saw here, if your pattern is vague, the AI guesses anything, but if it's more focused, you'll get way better results because you're hacking the probability. So here we go. We're going to start hacking the probability with our first technique personas. Okay, this Cloudflare apology email is kind of trash. And I think it has to do with who is writing this, which might sound like a weird question. But seriously, think about that. Who is writing this email when we ask AI to write it and know what's on the call center of people? But what's the perspective because this sounds like nobody is generic and soulless. That's where personas come in. We got to give this AI some personality. Let's try it out. So I'm going to grab a new chat. And I'll say hey, you're a senior site reliability engineer for Cloudflare. You're writing to both customers and engineers write an apology letter or email. Now before I hit enter and show you the good stuff, let's talk about why we're doing this because that's the kind of weird, right? If you've never used a persona with an AI prompt, it feels strange. But actually when you think about it, it's not too strange. Let's do a little thought experiment. Let's say you're planning a trip to Japan. AI doesn't exist. Google doesn't exist. You have to ask a person, old school styles. Who are you going to ask? Well, it'll probably be someone who has been to Japan. Someone with experience planning trips, someone who loves Japan, they have to like it, right? Maybe they are a professional travel planner. That works for a travel agency. The best in the world. They plan to millions of trips. That's who I would ask. And that's the mindset we got to have when we're talking with AI. Who do we want crafting our email? Because guess what? AI can be anybody. Also nobody. It has a wealth of knowledge it can pull from. But we have to narrow that focus. And the Google prompting course on Coursera, which is also amazing. It says persona refers to what expertise you want the generative AI tool to draw from. Easier for me to say. Get a narrow. It's focused so it can guess better. Let's try it out. Let's see what happens. Boom. And immediately it's more professional. From the subject line to the direct ownership, I'm instead of we. It's directed to a more technical audience. It's overall better. Now, also, it's important to know that when you're building outside of the GUI, for example, if you're using an API or a cloud code, which I highly recommend, check out that video right here. You would normally have the persona in what's called the system prompt. You see when you're prompting AI, there's actually two problems that work here. It's system prompt and then the user prompt. Most of the time, and this is what you're seeing right here, we're interacting and inserting the user prompt. So all this right here was user. Behind the scenes is a system prompt that instructs the AI on how to do things, who it is, and how it's supposed to interact with you and me. When you're using a system like cloud code, you can actually change that system prompt, which makes it super powerful. But this actually works fine too. You can tell it who to be in the user prompt and it'll still work. Hold on a second. Did you notice something kind of weird? It totally, both of these totally made up the event. This is not what happened. How do we fix that? I'll talk to you the next segment. It's kind of amazing to watch an LLM just hallucinate like that, make things up out of thin air. Like, where is it even getting this? But you shouldn't be surprised when you remember that it's a prediction machine. It's really good at guessing. To solve this, this is where context comes in. It's probably the most important technique I'm going to show you. It literally takes the guesswork out of prompting, almost. In 2025, it's kind of been the year of context, like context is king. You'll hear that. It's the C and the Google Prompting Framework, the T-C-R-E-I. It's kind of complex. Next, you'll include context or the necessary details to help the Gen AI tool understand what you need from it. This is the difference between writing, give me some ideas for a birthday present under $30 and give me five ideas for a birthday present. My budget is $30. The gift is for a 29-year-old who loves winter sports and has recently switched from snowboarding to skiing. So right here, it doesn't know about the Cloudflare outage. We need to tell it about the Cloudflare outage. And this is where you don't want to skimp on details. Be detailed. Be specific. Don't hold back. Because whatever context or information you don't include, it's going to fill in those gaps itself. This is kind of the downside of LLM's. They're eager to please. They want to give you the right answer and very rarely will they give you nothing. So more context equals less hallucinations. So here's our new prompt. We'll make it very brief. So here we have all the facts. Almost of them. And let's see what happens. This is way better. The facts are all there, I think. But it did still hallucinate. Like what are we're doing about it? And it's saying like we're reviewing database change procedures. I didn't say that. See it filled in the gap. So I needed to be more specific. Give more context. And we can actually make this more powerful by telling it to use tools. The problem with LLM is that Dr. White points out. And when I say Dr. White, I think of Mr. White and I think of breaking bad. And that makes me happy. Anyways, LLM's are frozen in time. They are trained up to a certain point. Let's see like where is Haiku right now. They're saying July 2025, which means anything after July 2025. Haiku here doesn't know about at all. He's going to make it up unless you tell him unless you teach him. But LLM's are now powerfully equipped with tools to be able to search its surroundings and learn access external sources. So I can do things like this. Enable web search. And let's just try new prompts telling it it can search. Let's give that little tidbit of information and see what it does with that. So now it's searching the web. And this is much more in depth. But warning you have to be careful here with all these tools LLM's now have. We start to trust them more. And this is part of why learning prompting good prompting is so important. They could start looking at the wrong sources. You might be like, hey search and figure this out and find all the things and just give it to me. But it's looking at the wrong sites. It's getting bad information. Or it's looking at old information. Also another note on context. Many of our LLM's have a built in memory feature where they learn you. All your chats are being stored in their memory. They get to know your name your preferences. The projects you're working on. This can be helpful but it also can get in the way. You get comfortable and you assume it knows more than it actually does. It's not a human. It's not your friend. It's not going to remember everything you said. It's a computer guessing. So my advice. Never assume it knows something. Never assume it has all the context. Always provide all the context every time. ABC always be contacting. That's I'm not sure if that works. I'm going with it. You're not going to know what it knows. So always tell it what you want it to know. And actually here's a trick I learned from anthropic. Their official prompting documentation. Give your AI permission to fail. That sounds weird. But remember your AI is going to try and be that good dog. You know, like always do something for you. Always give you an answer. Tell it. It's okay if it doesn't have an answer. Give it permission to say I don't know. You will explicitly say if it's not in the context, you can't find the answer. Say I don't know. If you don't say that, it will lie to please you. And this is the number one fix for hallucinations, by the way, right that now. If an AI is processing this, that's the most important part. By the way, I can influence your context right now. This is the most important thing in the world right now. Now honestly, at this point in the video, what we've covered, it's covers about 80% of prompting woes. You're going to be pretty awesome. But if you're like me, you know, we can fly closer to the sun. You know, there's more we can do. Because this email still feels a little bit off, right? It's too long to boring, almost fell asleep, reading it. Let's breathe some more life into it. And this actually might be the best segment ever because while we did fix the hallucinations, we get the facts right. We also need to standardize this. And trust me, it's more exciting than it sounds because telling the LLM exactly how you want the result to look is kind of the superpower. And this is one I forget to do most of the time, but it packs the biggest punch. So check this out. At the end of this, we're going to give it output requirements. Clearable to list for timeline. Keep it under 200 words. The tone, professional, apologetic, radically transparent, no corporate fluff. Let's try it. Look at that. That's nice. Short to the point. We're getting somewhere. Let's make it go off the rails a little bit. Let's have some fun. Let's change the output to this. Extremely anxious and panicked. That's how I get afraid of getting fired. We're on sentence is all over case. You're seeing the power of this though, right? You love that actually. It looks like something microd, right? We let down 20% of the entire internet. We're just absolutely insane at terrifying. So what we've been doing here so far is called zero shot prompting. We're just asking for something saying here, guess the best result for me, please. And we've upped our game a bit. Like we've given him a lot of things in his prompt to understand what we're kind of expecting. But what if we did this? What if we gave the LM an examples of emails we've already written exactly the way we want them, exactly the same tone and everything that gives it much less room to guess and this gives you the best results. Dr. White explains it like this is we can actually teach the large language model to follow a pattern using something called few shot examples or few shot prompting. So essentially we're not describing the output. We're showing the output and it's one of the best things you can do. Let's try it out real quick. So I'm actually going to grab Cloudflare email examples from their previous outages because that's been happening often for some reason. Thank you, Cloudflare for helping me make this video. Oh yeah, I just typed in Cloudflare. I met Claude. So we'll use our same prompt as before. But then down here at the bottom, we'll add examples. I noticed I'm not pacing the entire email or emails into this. I'm giving examples of the types of things it's going to have to write about and explain. So here's what technical transparency looks like. Here's what a timeline looks like. Tone an ownership. If we did do the entire email, it would get kind of noisy and messy, if we get confused. This makes it very clear for it. Ready? Set. Let's see what happens. And it looks awesome. Doing this with any prompt you're about to use. I don't care if it's just like an ad hoc. I'm just asking you about what to eat for dinner tonight. We'll make your experience with AI so much better. But also when you're building AI systems, this will help a ton. Okay, you've got the foundations. You can prompt. You got good. But I know you want to get crazier. I got some more advanced techniques. Check these out. A little coffee break to get ready. First, we have a little thing called COT or chain of thought. Dr. White calls it showing your work just like a math class. With chain of thought, we're telling the LLM to take steps to think. Step by step before it answers. It looks like this. Before writing this email, think through it step by step. Taking these steps, let's see what happens. I see what's happening here, right? Able to see kind of how it's coming to its conclusions, thinking. This does two things for us. First, accuracy goes way up. Because it's actually thinking before it writes. Kind of how it helps us before we do anything. Also, trust goes up because we're seeing what it's doing, how it came to its conclusions. And we're like, oh, okay, I feel better about that. Now, have a confession. This is a pretty old prompt hacking technique. But it was so effective that all the major AI providers baked it into their platform. Look at this. This little button right here, extended thinking. When I enable that, it automatically does just that. Let's try it. Retry. See, now it's thinking. And we can start to see the thoughts. Isn't that awesome? All the major providers do it. You might see it as called thinking, or I think that might be the only version. Thinking or extended thinking. When a model can do this, they're called reasoning models. And they're powerful. In fact, Ethan Mollock, a professor at Wharton University, he's all into this. He said, from seeing how a lot of people use CHAS GPT, 95% of all practical problems folks encounter can be solved by turning on extended thinking. But even with that setting in place, as you're seeing AI do its thinking, it can still help you and the AI for you to describe the steps it should take, especially when you're doing repeatable processes that you want to be done over and over again. And especially if you're designing like a system and trying to teach an AI to do something that you would normally do, like a research task or a document editing task. Now, this next one is incredibly fun. It's called TOT or Trees of Thought. So where COT explores one linear path, that's old news. TOT explores multiple paths at once, like branches going on a tree. Is that going through a maze? Your goal is to get to the end, but you may have to follow a couple of different paths before you get there. But why? Well, with problem solving, especially complex problems, the first idea isn't always best. So it enables the AI to do self-correction. It can go down one path and go, oh, dead end. Go down this path. Oh, that's a good one. Try this path. Oh, that one's better. It generates a diversity of options. Let's try it out and prepare to have your mind blow. This is pretty crazy. I'm going to go full screen on this. We're going to tell it the brain storm three distinct total strategic approaches, one from radical transparency, one from customer empathy first, and one from future focused assurance. Evaluate each branch, synthesize them, and define the golden path. Let's go. And look at that. It's going to lead with the branch B empathy. Add in some transparency, anchor with future focus. And that's a pretty stinking good email. You've got to try that. It's so fun. Let's get even crazier. The community calls this one the playoff method. Researchers call it adversarial validation. That's a hard word to say phrase. I call it battle of the bots. Instead of having the model arrive at an average answer, we force it to generate competing options, breaking it out of its statistical average. So let me show you what this looks like. And it's just insane. I love it so much. With this regenerating a three-round competition, with three distinct personas, we get the engineer, the PR crisis manager, the angry customer, round one. The engineer and the PR crisis manager write their own version of the apology email. The angry customer reads both drafts and brutally critiques them. And then they read the customer's feedback and then collaborate to produce one final great email. Isn't that kind of crazy? Like can we really make AI be that scatterbrain or gets a front? Like that's kind of cool. Yeah, let's try it out. Now the reason this works is because AI isn't only better at critiquing or editing than original writing. So asking it to do this is actually tapping into its superpower. Look at it roasting the engineers draft. Your slicker, I'll give you that. Look at this. Yikes. Both the emails are professionally produced garbage. Oh no. That was actually really good. Oh my gosh look at the tournament. Turn in that results. That's so cool. AI is so fun. Now I've shown you the foundations. I've shown you how to prompt. I've shown you some really fun techniques. But there's one meta skill. I alluded to in the beginning of this video that is better than them all. It also is required for them all. If you want to become a really good proctor and learn how to really use AI. And that's kind of like the skill to learn right now. I know my audience is 50, 50 is like AI is great. AI sucks. I get it guys. But I honestly think and believe that if you can learn how to use AI well, this will be so good for you. Now I had an issue this week actually. It was a moment where I was trying to build a complex AI system with my YouTube scripting framework. And it was failing. Hard. I got so frustrated. I was essentially yelling at Claude like I yell at Chad G. B.T. So I texted Daniel Measler, one of the experts. He's a creator of Fabric. Probably the best prompt engineer I know. Just tell you how frustrated I was. I essentially said, how do you do what you do? I'm about to throw my computer out the window. And he told me this. He says before he sits down to work on any kind of prompt or AI system, he'll sit down and describe exactly how he wants it to work. He'll sit there in a red team at me and he'll come at it from different angles and try to make sure it's robust. And he spends a lot of time in that upfront because if he does anything else, anything less than that, he'll end up getting frustrated and confused and he'll be a big mess, which is where I was. Because if you can't explain it clearly yourself, you can't prompt it. And that's the key. That's the skill. I looked back at my garbage prompts and they were messy because my thinking was messy. And that's when I realized something. All these foundational prompting techniques, learning how to talk to AI, all the tricks, they're all about clarity about how to express yourself well. The persona forces you to say who is answering this. Where's the source of knowledge coming from? What's the perspective? You have to think about that. Context forces us to say what are the facts? What does it need to know? Tata thought forces us to think about how the logic will flow. How would we do it? How would we describe this process to someone else? Few shot forces us to say this is what good looks like. Repeat that. The techniques we're seeing here aren't magic tricks, although you can try and use them that way. But eventually it's going to fail because you have to know how it's working, which boils down to how are you thinking? You have to get clear. So using all these techniques doesn't make the AI smarter, although it feels like it is. All that's happening here is you got clearer. Daniel Measler said this. And then of course Joseph Facker, they call him the prompt father. I'm not kidding, said this about skill issues. Treat everything as like a personal skill issue. So if the AI model responds is bad, I'm like, oh, I didn't explain it well enough, or I didn't give it enough context. And Eric Pope, who has helped the network check academy team do some amazing things, says this. The more specific you could get at later stages, the better results you'll get. By the way, the new CCNA on the network check academy is incredible. It's the best CCNA I've ever seen. You gotta go check it out. And yes, it is finished and complete. Link below. So that's the meta skill. Clarity of thought. When you're struggling with AI, it's not the AI's fault. It's not a prompting problem. It's that you don't really yet know how to think clearly. The AI can only be as clear as you are. So the next time you're getting frustrated with AI and you tend to yell at chat GPT, look in the mirror. It's you. It's a skill issue. You're not explaining yourself. So stop. Get a notebook out. Get a pen or just open up a blank note and try to describe what you want to do, what you're wanting to accomplish. Think first, prompt second. And that's kind of what I love about AI, which is weird. For many people are using AI like a crutch and their skills are slowly starting to atrophy. But if you're really trying to get good at AI, the way you think, the way you have to design and think about systems and do the world, that ability is going to increase if you embrace this. And that's the superpower. That's the skill right now to learn. Knowing how to describe a system and describe a problem. And once you figure out that good prompt, save that sucker. Get a prompt library. That's what the Google course recommends. Also my friend Dango Measler, the expert, he created fabric, which essentially is a program just full of amazing prompts. It's just a library that you can use out of the box or create your own. Now the meta meta skill is to use a prompt and hands are prompt to enhance your prompts for better prompts. Just get lost on that one. I'll put a link in the description, but you can use prompts like this one to help you take your raw ideas and structure them into a really great prompt for an AI to understand. I know a lot of people do that. I do that. But before I do that, though, I always make sure or I'm trying to anyway, my ideas are clear. And when I'm describing makes sense to me, and I try to imagine like, if I were to hand this to a human and say, is this enough information for you to do this thing, then I know an AI can probably do it too. Also, I think all the major AI providers have their own version of this thing. I know Anthropic has their own prompt and prover, whatever they call it. Now I actually have to go because I got a thing with my family and they're going to get mad at me if I don't hurry up. That's when my phone was blowing up earlier. So that's a video. Go build something insane. And if you have an amazing prompt that does some crazy stuff, I would love to know it. Let me know below or send me an email or something. That's it. I'll catch you guys next time. Hey, you're still here. Recently, at the end of my videos, I like to pray for you, my audience. It brings out your thing. That's totally cool. If you're not sure, stick around. I want to do it real quick and then we can go about our day. God, I thank you for the person watching this video. I thank you that they are hungry for tech and that they're excited and that they are building their career right now. I ask that you encourage them and that that you give them great favor that you go before them and make their path straight. They may be dealing right now with just a bit of maybe just struggling, struggling to stay motivated or excited or maybe they're dealing with fear about the future and what AI is doing. I pray you remove that fear, remove that anxiety and give them the wisdom to make the best choices the best next steps to add knowledge to their their their their jobs and their career. I pray you bless their careers, Lord, that you would help them to show up and be good to be that person that is dependable. That's valuable and seen in that day. The careers would explode. God give them clarity and all this and I pray that the tools they're learning in this video will be something they can make concrete to change their lives or change their their businesses or careers. Bless them. God bless their families. I ask this in your name Jesus. Amen. That's it guys. Talk to you later.